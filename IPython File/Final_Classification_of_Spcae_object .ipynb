{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load and preproceesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('New Text Document.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(data.columns[[0,1,2,8,9,10,11,12]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(data.columns[[6,7,8,9]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Encode categorical integer features using a one-hot aka one-of-K scheme.\n",
    "The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) features. The output will be a sparse matrix where each column corresponds to one possible value of one feature. It is assumed that input features take on values in the range [0, n_values).\n",
    "This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"GALAXY\", \"QSO\", \"STAR\"])\n",
    "le.transform([\"GALAXY\", \"QSO\", \"STAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['class'] = le.fit_transform(data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e85b5ec95f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;31m# Plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   3776\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   3777\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3778\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   3779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[1;32m   2381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# df.groupby('name')\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m             \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2384\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Prakritidev Verma\\Anaconda3\\envs\\py27\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1974)\n",
    "\n",
    "# Generate Data\n",
    "num = 20\n",
    "x, y = np.random.random((2, num))\n",
    "labels = np.random.choice(['a', 'b', 'c'], num)\n",
    "df = pd.DataFrame(dict(x=x, y=y, label=labels))\n",
    "\n",
    "groups = df.groupby('class')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(data, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing outiers from the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Cleaning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.05989</td>\n",
       "      <td>17.49459</td>\n",
       "      <td>16.59285</td>\n",
       "      <td>16.09412</td>\n",
       "      <td>15.70741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.45567</td>\n",
       "      <td>18.33084</td>\n",
       "      <td>17.67185</td>\n",
       "      <td>17.30189</td>\n",
       "      <td>17.13650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.27065</td>\n",
       "      <td>18.08745</td>\n",
       "      <td>18.08966</td>\n",
       "      <td>18.22180</td>\n",
       "      <td>18.37045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.94490</td>\n",
       "      <td>17.45382</td>\n",
       "      <td>16.71061</td>\n",
       "      <td>16.26543</td>\n",
       "      <td>15.94860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.26457</td>\n",
       "      <td>16.76603</td>\n",
       "      <td>16.19773</td>\n",
       "      <td>15.99331</td>\n",
       "      <td>15.90720</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.84868</td>\n",
       "      <td>16.86433</td>\n",
       "      <td>15.90334</td>\n",
       "      <td>15.42890</td>\n",
       "      <td>15.08823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.43880</td>\n",
       "      <td>18.36549</td>\n",
       "      <td>17.84352</td>\n",
       "      <td>17.62595</td>\n",
       "      <td>17.54450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.37425</td>\n",
       "      <td>17.76414</td>\n",
       "      <td>17.10439</td>\n",
       "      <td>16.85696</td>\n",
       "      <td>16.71100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.88025</td>\n",
       "      <td>17.73751</td>\n",
       "      <td>18.04885</td>\n",
       "      <td>18.32398</td>\n",
       "      <td>18.52942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.03113</td>\n",
       "      <td>17.93515</td>\n",
       "      <td>17.49739</td>\n",
       "      <td>17.15799</td>\n",
       "      <td>16.99095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.34175</td>\n",
       "      <td>18.33376</td>\n",
       "      <td>17.95975</td>\n",
       "      <td>17.67543</td>\n",
       "      <td>17.54168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.20547</td>\n",
       "      <td>18.21573</td>\n",
       "      <td>17.73127</td>\n",
       "      <td>17.42313</td>\n",
       "      <td>17.32267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.44517</td>\n",
       "      <td>17.24542</td>\n",
       "      <td>17.10835</td>\n",
       "      <td>17.09101</td>\n",
       "      <td>17.13442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.62963</td>\n",
       "      <td>16.91113</td>\n",
       "      <td>16.21830</td>\n",
       "      <td>15.97996</td>\n",
       "      <td>15.83835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.73878</td>\n",
       "      <td>17.51475</td>\n",
       "      <td>17.05004</td>\n",
       "      <td>16.84725</td>\n",
       "      <td>16.77919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.62952</td>\n",
       "      <td>14.88339</td>\n",
       "      <td>14.55241</td>\n",
       "      <td>14.57238</td>\n",
       "      <td>15.26632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.24598</td>\n",
       "      <td>15.93616</td>\n",
       "      <td>15.44045</td>\n",
       "      <td>15.25684</td>\n",
       "      <td>15.18487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.98141</td>\n",
       "      <td>17.65929</td>\n",
       "      <td>17.21067</td>\n",
       "      <td>17.04889</td>\n",
       "      <td>17.00209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.16411</td>\n",
       "      <td>17.27371</td>\n",
       "      <td>16.31466</td>\n",
       "      <td>15.78471</td>\n",
       "      <td>15.44008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.71818</td>\n",
       "      <td>17.39557</td>\n",
       "      <td>16.87677</td>\n",
       "      <td>16.71544</td>\n",
       "      <td>16.62775</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19.30350</td>\n",
       "      <td>17.90728</td>\n",
       "      <td>17.25062</td>\n",
       "      <td>16.85490</td>\n",
       "      <td>16.58678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18.81831</td>\n",
       "      <td>17.68695</td>\n",
       "      <td>17.54415</td>\n",
       "      <td>17.54516</td>\n",
       "      <td>17.60621</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.31649</td>\n",
       "      <td>17.11621</td>\n",
       "      <td>16.60212</td>\n",
       "      <td>16.44939</td>\n",
       "      <td>16.38380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.17672</td>\n",
       "      <td>17.01050</td>\n",
       "      <td>16.41779</td>\n",
       "      <td>16.03847</td>\n",
       "      <td>15.84439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.87921</td>\n",
       "      <td>17.12427</td>\n",
       "      <td>16.25532</td>\n",
       "      <td>15.85055</td>\n",
       "      <td>15.55597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18.95872</td>\n",
       "      <td>17.04945</td>\n",
       "      <td>16.16656</td>\n",
       "      <td>15.71334</td>\n",
       "      <td>15.41194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18.89983</td>\n",
       "      <td>17.45141</td>\n",
       "      <td>16.81735</td>\n",
       "      <td>16.60699</td>\n",
       "      <td>16.46253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.08604</td>\n",
       "      <td>17.34755</td>\n",
       "      <td>16.35862</td>\n",
       "      <td>15.84222</td>\n",
       "      <td>15.47503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.97039</td>\n",
       "      <td>18.81752</td>\n",
       "      <td>18.68532</td>\n",
       "      <td>18.60291</td>\n",
       "      <td>18.33350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.09687</td>\n",
       "      <td>17.18067</td>\n",
       "      <td>16.23233</td>\n",
       "      <td>15.81135</td>\n",
       "      <td>15.49600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499970</th>\n",
       "      <td>17.82531</td>\n",
       "      <td>16.05176</td>\n",
       "      <td>15.20068</td>\n",
       "      <td>14.78909</td>\n",
       "      <td>14.46594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499971</th>\n",
       "      <td>18.86337</td>\n",
       "      <td>17.37860</td>\n",
       "      <td>16.46882</td>\n",
       "      <td>15.92749</td>\n",
       "      <td>15.55472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499972</th>\n",
       "      <td>19.25006</td>\n",
       "      <td>17.96285</td>\n",
       "      <td>17.33656</td>\n",
       "      <td>16.99463</td>\n",
       "      <td>16.71178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499973</th>\n",
       "      <td>18.93172</td>\n",
       "      <td>18.02538</td>\n",
       "      <td>17.45272</td>\n",
       "      <td>17.01181</td>\n",
       "      <td>16.76630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499974</th>\n",
       "      <td>19.57897</td>\n",
       "      <td>18.71716</td>\n",
       "      <td>18.29935</td>\n",
       "      <td>18.05411</td>\n",
       "      <td>17.97670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499975</th>\n",
       "      <td>18.03049</td>\n",
       "      <td>16.64616</td>\n",
       "      <td>15.94447</td>\n",
       "      <td>15.56295</td>\n",
       "      <td>15.27652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499976</th>\n",
       "      <td>18.95551</td>\n",
       "      <td>17.26273</td>\n",
       "      <td>16.45864</td>\n",
       "      <td>16.06700</td>\n",
       "      <td>15.77411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499977</th>\n",
       "      <td>18.90054</td>\n",
       "      <td>17.46412</td>\n",
       "      <td>17.00567</td>\n",
       "      <td>16.64863</td>\n",
       "      <td>16.48117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499978</th>\n",
       "      <td>17.60430</td>\n",
       "      <td>16.48509</td>\n",
       "      <td>16.11953</td>\n",
       "      <td>15.91252</td>\n",
       "      <td>15.85446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499979</th>\n",
       "      <td>18.61886</td>\n",
       "      <td>16.90519</td>\n",
       "      <td>16.00957</td>\n",
       "      <td>15.59416</td>\n",
       "      <td>15.20120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499980</th>\n",
       "      <td>19.07203</td>\n",
       "      <td>18.50355</td>\n",
       "      <td>18.24000</td>\n",
       "      <td>18.21894</td>\n",
       "      <td>18.12175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499981</th>\n",
       "      <td>19.53868</td>\n",
       "      <td>18.15689</td>\n",
       "      <td>17.54798</td>\n",
       "      <td>17.19483</td>\n",
       "      <td>16.98530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499982</th>\n",
       "      <td>19.45609</td>\n",
       "      <td>19.32263</td>\n",
       "      <td>19.24986</td>\n",
       "      <td>18.98923</td>\n",
       "      <td>18.91439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499983</th>\n",
       "      <td>19.07372</td>\n",
       "      <td>18.04145</td>\n",
       "      <td>17.39985</td>\n",
       "      <td>17.02994</td>\n",
       "      <td>16.81062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499984</th>\n",
       "      <td>19.01428</td>\n",
       "      <td>17.13976</td>\n",
       "      <td>16.11478</td>\n",
       "      <td>15.63975</td>\n",
       "      <td>15.24344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499985</th>\n",
       "      <td>18.78449</td>\n",
       "      <td>17.02557</td>\n",
       "      <td>16.09566</td>\n",
       "      <td>15.68379</td>\n",
       "      <td>15.35543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499986</th>\n",
       "      <td>19.19143</td>\n",
       "      <td>18.03955</td>\n",
       "      <td>17.50952</td>\n",
       "      <td>17.23531</td>\n",
       "      <td>17.03402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>18.57335</td>\n",
       "      <td>18.35490</td>\n",
       "      <td>18.32511</td>\n",
       "      <td>18.38922</td>\n",
       "      <td>18.20812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499988</th>\n",
       "      <td>19.57250</td>\n",
       "      <td>18.25274</td>\n",
       "      <td>17.73394</td>\n",
       "      <td>17.36947</td>\n",
       "      <td>17.20335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499989</th>\n",
       "      <td>19.43531</td>\n",
       "      <td>17.53491</td>\n",
       "      <td>16.59192</td>\n",
       "      <td>16.16469</td>\n",
       "      <td>15.84496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>18.89643</td>\n",
       "      <td>17.47071</td>\n",
       "      <td>16.88147</td>\n",
       "      <td>16.65541</td>\n",
       "      <td>16.53781</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>19.52056</td>\n",
       "      <td>17.54191</td>\n",
       "      <td>16.36136</td>\n",
       "      <td>15.86862</td>\n",
       "      <td>15.49105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499992</th>\n",
       "      <td>17.95698</td>\n",
       "      <td>16.33865</td>\n",
       "      <td>15.67617</td>\n",
       "      <td>15.40413</td>\n",
       "      <td>15.27109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499993</th>\n",
       "      <td>19.07541</td>\n",
       "      <td>16.60918</td>\n",
       "      <td>15.64256</td>\n",
       "      <td>15.30070</td>\n",
       "      <td>15.13256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>17.35504</td>\n",
       "      <td>15.53525</td>\n",
       "      <td>14.72662</td>\n",
       "      <td>14.33282</td>\n",
       "      <td>14.06379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>18.96836</td>\n",
       "      <td>17.32873</td>\n",
       "      <td>16.48102</td>\n",
       "      <td>15.98196</td>\n",
       "      <td>15.63491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>18.00649</td>\n",
       "      <td>16.45442</td>\n",
       "      <td>15.83506</td>\n",
       "      <td>15.61025</td>\n",
       "      <td>15.46043</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>18.31123</td>\n",
       "      <td>17.24955</td>\n",
       "      <td>16.76237</td>\n",
       "      <td>16.55457</td>\n",
       "      <td>16.44842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>18.54049</td>\n",
       "      <td>17.07246</td>\n",
       "      <td>16.52143</td>\n",
       "      <td>16.31161</td>\n",
       "      <td>16.21008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>19.29351</td>\n",
       "      <td>17.64427</td>\n",
       "      <td>16.91061</td>\n",
       "      <td>16.60851</td>\n",
       "      <td>16.42730</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499996 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               u         g         r         i         z  class\n",
       "0       19.05989  17.49459  16.59285  16.09412  15.70741      0\n",
       "1       19.45567  18.33084  17.67185  17.30189  17.13650      0\n",
       "2       18.27065  18.08745  18.08966  18.22180  18.37045      1\n",
       "3       18.94490  17.45382  16.71061  16.26543  15.94860      0\n",
       "4       18.26457  16.76603  16.19773  15.99331  15.90720      2\n",
       "5       18.84868  16.86433  15.90334  15.42890  15.08823      0\n",
       "6       19.43880  18.36549  17.84352  17.62595  17.54450      2\n",
       "7       19.37425  17.76414  17.10439  16.85696  16.71100      2\n",
       "8       17.88025  17.73751  18.04885  18.32398  18.52942      2\n",
       "9       19.03113  17.93515  17.49739  17.15799  16.99095      0\n",
       "10      19.34175  18.33376  17.95975  17.67543  17.54168      0\n",
       "11      19.20547  18.21573  17.73127  17.42313  17.32267      0\n",
       "12      18.44517  17.24542  17.10835  17.09101  17.13442      2\n",
       "13      18.62963  16.91113  16.21830  15.97996  15.83835      2\n",
       "14      18.73878  17.51475  17.05004  16.84725  16.77919      2\n",
       "15      16.62952  14.88339  14.55241  14.57238  15.26632      0\n",
       "16      17.24598  15.93616  15.44045  15.25684  15.18487      2\n",
       "17      18.98141  17.65929  17.21067  17.04889  17.00209      2\n",
       "18      19.16411  17.27371  16.31466  15.78471  15.44008      0\n",
       "19      18.71818  17.39557  16.87677  16.71544  16.62775      2\n",
       "20      19.30350  17.90728  17.25062  16.85490  16.58678      0\n",
       "21      18.81831  17.68695  17.54415  17.54516  17.60621      2\n",
       "22      18.31649  17.11621  16.60212  16.44939  16.38380      2\n",
       "23      18.17672  17.01050  16.41779  16.03847  15.84439      0\n",
       "24      18.87921  17.12427  16.25532  15.85055  15.55597      0\n",
       "25      18.95872  17.04945  16.16656  15.71334  15.41194      0\n",
       "26      18.89983  17.45141  16.81735  16.60699  16.46253      2\n",
       "27      19.08604  17.34755  16.35862  15.84222  15.47503      0\n",
       "28      18.97039  18.81752  18.68532  18.60291  18.33350      1\n",
       "29      19.09687  17.18067  16.23233  15.81135  15.49600      0\n",
       "...          ...       ...       ...       ...       ...    ...\n",
       "499970  17.82531  16.05176  15.20068  14.78909  14.46594      0\n",
       "499971  18.86337  17.37860  16.46882  15.92749  15.55472      0\n",
       "499972  19.25006  17.96285  17.33656  16.99463  16.71178      0\n",
       "499973  18.93172  18.02538  17.45272  17.01181  16.76630      0\n",
       "499974  19.57897  18.71716  18.29935  18.05411  17.97670      0\n",
       "499975  18.03049  16.64616  15.94447  15.56295  15.27652      0\n",
       "499976  18.95551  17.26273  16.45864  16.06700  15.77411      0\n",
       "499977  18.90054  17.46412  17.00567  16.64863  16.48117      0\n",
       "499978  17.60430  16.48509  16.11953  15.91252  15.85446      0\n",
       "499979  18.61886  16.90519  16.00957  15.59416  15.20120      0\n",
       "499980  19.07203  18.50355  18.24000  18.21894  18.12175      1\n",
       "499981  19.53868  18.15689  17.54798  17.19483  16.98530      0\n",
       "499982  19.45609  19.32263  19.24986  18.98923  18.91439      1\n",
       "499983  19.07372  18.04145  17.39985  17.02994  16.81062      0\n",
       "499984  19.01428  17.13976  16.11478  15.63975  15.24344      0\n",
       "499985  18.78449  17.02557  16.09566  15.68379  15.35543      0\n",
       "499986  19.19143  18.03955  17.50952  17.23531  17.03402      0\n",
       "499987  18.57335  18.35490  18.32511  18.38922  18.20812      1\n",
       "499988  19.57250  18.25274  17.73394  17.36947  17.20335      0\n",
       "499989  19.43531  17.53491  16.59192  16.16469  15.84496      0\n",
       "499990  18.89643  17.47071  16.88147  16.65541  16.53781      2\n",
       "499991  19.52056  17.54191  16.36136  15.86862  15.49105      0\n",
       "499992  17.95698  16.33865  15.67617  15.40413  15.27109      2\n",
       "499993  19.07541  16.60918  15.64256  15.30070  15.13256      2\n",
       "499994  17.35504  15.53525  14.72662  14.33282  14.06379      0\n",
       "499995  18.96836  17.32873  16.48102  15.98196  15.63491      0\n",
       "499996  18.00649  16.45442  15.83506  15.61025  15.46043      2\n",
       "499997  18.31123  17.24955  16.76237  16.55457  16.44842      2\n",
       "499998  18.54049  17.07246  16.52143  16.31161  16.21008      2\n",
       "499999  19.29351  17.64427  16.91061  16.60851  16.42730      2\n",
       "\n",
       "[499996 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['i'] > -200]\n",
    "data[data['z'] > -200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data['class']\n",
    "features = data.drop('class', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Metric and accuracy metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def performance_martix(pred, y_test):\n",
    "    \n",
    "    score = accuracy_score(pred, y_test)\n",
    "    print('The Accuracy is \\n')\n",
    "    print(score)\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def clf_report(pred, y_test):\n",
    "    report = classification_report(pred, y_test)\n",
    "    print('Full Classification report :')\n",
    "    print(report)\n",
    "    return \n",
    "\n",
    "def fit_and_predict(clf,X_train,y_train,X_test,y_test):\n",
    "    print('Traning Model........')\n",
    "    clf.fit(X_train,y_train)\n",
    "    print('Model Trained........')\n",
    "    pred = clf.predict(X_test)\n",
    "    print('accuracy and classification report:')\n",
    "    \n",
    "    performance_martix(pred,y_test)\n",
    "    clf_report(pred,y_test)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ensemble methods are learning algorithms that construct a. set of classifiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian aver- aging, but more recent algorithms include error-correcting output coding, Bagging, and boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaboostClassifier with DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Model\n",
      "Model trained\n",
      "The Accuracy is \n",
      "\n",
      "0.77912\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84     13790\n",
      "          1       0.86      0.72      0.79      2535\n",
      "          2       0.76      0.57      0.65      8675\n",
      "\n",
      "avg / total       0.78      0.78      0.77     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Adaclf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),algorithm=\"SAMME\",n_estimators=200)\n",
    "print('Traning Model')\n",
    "Adaclf.fit(X_train,y_train)\n",
    "print('Model trained')\n",
    "y_pred = Adaclf.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.77912\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84     13790\n",
      "          1       0.86      0.72      0.79      2535\n",
      "          2       0.76      0.57      0.65      8675\n",
      "\n",
      "avg / total       0.78      0.78      0.77     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clfGBC = GradientBoostingClassifier()\n",
    "clfGBC.fit(X_train,y_train)\n",
    "y_pred = Adaclf.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gausian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.54324\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.78      0.71     13790\n",
      "          1       0.31      0.90      0.46      2535\n",
      "          2       0.46      0.07      0.12      8675\n",
      "\n",
      "avg / total       0.55      0.54      0.48     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NBclf = GaussianNB()\n",
    "NBclf.fit(X_train,y_train)\n",
    "NBclf.predict(X_train)\n",
    "y_pred = NBclf.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.96068\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     13790\n",
      "          1       0.94      0.93      0.93      2535\n",
      "          2       0.96      0.95      0.95      8675\n",
      "\n",
      "avg / total       0.96      0.96      0.96     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfR = RandomForestClassifier()\n",
    "clfR.fit(X_train,y_train)\n",
    "y_pred = clfR.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.83544\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87     13790\n",
      "          1       0.90      0.78      0.84      2535\n",
      "          2       0.83      0.71      0.77      8675\n",
      "\n",
      "avg / total       0.84      0.84      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.83544\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.92      0.87     13790\n",
      "          1       0.90      0.78      0.84      2535\n",
      "          2       0.83      0.71      0.77      8675\n",
      "\n",
      "avg / total       0.84      0.84      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "clfLR = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "GridSearchCV(cv=None,estimator=LogisticRegression(C=1.0, intercept_scaling=1, dual=False, fit_intercept=True, penalty='l2', tol=0.0001),param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]})\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.60888\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.96      0.74     13790\n",
      "          1       0.72      0.51      0.60      2535\n",
      "          2       0.57      0.07      0.13      8675\n",
      "\n",
      "avg / total       0.60      0.61      0.51     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = sgdclf.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent - SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Model\n",
      "\n",
      "\n",
      "Model trained\n",
      "The Accuracy is \n",
      "\n",
      "0.60888\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.96      0.74     13790\n",
      "          1       0.72      0.51      0.60      2535\n",
      "          2       0.57      0.07      0.13      8675\n",
      "\n",
      "avg / total       0.60      0.61      0.51     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdclf = SGDClassifier()\n",
    "print('Traning Model')\n",
    "print('\\n')\n",
    "sgdclf.fit(X_train,y_train)\n",
    "print('Model trained')\n",
    "y_pred = sgdclf.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is \n",
      "\n",
      "0.60888\n",
      "Full Classification report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.96      0.74     13790\n",
      "          1       0.72      0.51      0.60      2535\n",
      "          2       0.57      0.07      0.13      8675\n",
      "\n",
      "avg / total       0.60      0.61      0.51     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clfMLP = MLPClassifier(hidden_layer_sizes=(15,), random_state=1, max_iter=1, warm_start=True)\n",
    "clfMLP.fit(X_train, y_train)   \n",
    "y_pred = sgdclf.predict(X_test)\n",
    "performance_martix(y_test, y_pred)\n",
    "clf_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization using grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "()\n",
      "{'n_neighbors': 3}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.948 (+/-0.000) for {'n_neighbors': 1}\n",
      "0.946 (+/-0.001) for {'n_neighbors': 2}\n",
      "0.956 (+/-0.000) for {'n_neighbors': 3}\n",
      "0.956 (+/-0.000) for {'n_neighbors': 4}\n",
      "0.956 (+/-0.000) for {'n_neighbors': 5}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97     13790\n",
      "          1       0.95      0.92      0.93      2535\n",
      "          2       0.95      0.96      0.96      8675\n",
      "\n",
      "avg / total       0.96      0.96      0.96     25000\n",
      "\n",
      "()\n",
      "0.96028\n",
      "# Tuning hyper-parameters for recall\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "()\n",
      "{'n_neighbors': 3}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.948 (+/-0.000) for {'n_neighbors': 1}\n",
      "0.946 (+/-0.001) for {'n_neighbors': 2}\n",
      "0.956 (+/-0.000) for {'n_neighbors': 3}\n",
      "0.956 (+/-0.000) for {'n_neighbors': 4}\n",
      "0.956 (+/-0.000) for {'n_neighbors': 5}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97     13790\n",
      "          1       0.95      0.92      0.93      2535\n",
      "          2       0.95      0.96      0.96      8675\n",
      "\n",
      "avg / total       0.96      0.96      0.96     25000\n",
      "\n",
      "()\n",
      "0.96028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "k = np.arange(5)+1\n",
    "parameters = {'n_neighbors': k}\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(knn, parameters, cv=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "()\n",
      "{'kernel': 'linear', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.190 (+/-0.001) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.190 (+/-0.001) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.780 (+/-0.037) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.190 (+/-0.001) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.854 (+/-0.033) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.778 (+/-0.041) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.896 (+/-0.050) for {'kernel': 'linear', 'C': 1, 'gamma': 0.001}\n",
      "0.896 (+/-0.050) for {'kernel': 'linear', 'C': 1, 'gamma': 0.0001}\n",
      "0.923 (+/-0.045) for {'kernel': 'linear', 'C': 10, 'gamma': 0.001}\n",
      "0.923 (+/-0.045) for {'kernel': 'linear', 'C': 10, 'gamma': 0.0001}\n",
      "0.932 (+/-0.028) for {'kernel': 'linear', 'C': 100, 'gamma': 0.001}\n",
      "0.932 (+/-0.028) for {'kernel': 'linear', 'C': 100, 'gamma': 0.0001}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96     13790\n",
      "          1       0.91      0.85      0.88      2535\n",
      "          2       0.93      0.95      0.94      8675\n",
      "\n",
      "avg / total       0.94      0.94      0.94     25000\n",
      "\n",
      "0.94136\n",
      "()\n",
      "# Tuning hyper-parameters for recall\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "()\n",
      "{'kernel': 'linear', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.333 (+/-0.000) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.333 (+/-0.000) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.714 (+/-0.080) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.333 (+/-0.000) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.854 (+/-0.063) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.712 (+/-0.079) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.913 (+/-0.034) for {'kernel': 'linear', 'C': 1, 'gamma': 0.001}\n",
      "0.913 (+/-0.034) for {'kernel': 'linear', 'C': 1, 'gamma': 0.0001}\n",
      "0.927 (+/-0.027) for {'kernel': 'linear', 'C': 10, 'gamma': 0.001}\n",
      "0.927 (+/-0.027) for {'kernel': 'linear', 'C': 10, 'gamma': 0.0001}\n",
      "0.934 (+/-0.023) for {'kernel': 'linear', 'C': 100, 'gamma': 0.001}\n",
      "0.934 (+/-0.023) for {'kernel': 'linear', 'C': 100, 'gamma': 0.0001}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96     13790\n",
      "          1       0.91      0.85      0.88      2535\n",
      "          2       0.93      0.95      0.94      8675\n",
      "\n",
      "avg / total       0.94      0.94      0.94     25000\n",
      "\n",
      "0.94136\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train[:200], y_train[:200])\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
